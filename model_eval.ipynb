{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-3A4DgELyZR"
      },
      "source": [
        "# **Evaluating the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO8YbBcNJrJ"
      },
      "source": [
        "## **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJI04kEgE9oB"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "# Google Colab specific imports\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Package for DenseNet\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkPdLmOIFj1M",
        "outputId": "cc45e07d-180c-4493-f7ad-09703951cb12"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WtM-W2RGSiO"
      },
      "outputs": [],
      "source": [
        "# Global variables\n",
        "train_generator = None\n",
        "val_generator = None\n",
        "model = None\n",
        "base_model = None\n",
        "class_names = None\n",
        "\n",
        "# File paths\n",
        "FULL_DATA_PATH = path_to_your_dataset\n",
        "model_path = path_to_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBca-tLXZ-r1"
      },
      "source": [
        "# **load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztzD3mw6G8Q-"
      },
      "outputs": [],
      "source": [
        "def data_preprocess():\n",
        "    global train_generator, val_generator, train_dataset, val_dataset, class_names\n",
        "\n",
        "    dataset_path = FULL_DATA_PATH\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        tf.keras.layers.RandomRotation(0.3),  # Increased rotation randomness\n",
        "        tf.keras.layers.RandomZoom(0.3),      # Increased zoom randomness\n",
        "        tf.keras.layers.RandomContrast(0.2),  # Add random contrast adjustments\n",
        "        tf.keras.layers.RandomBrightness(0.2),  # Add random brightness adjustments\n",
        "        tf.keras.layers.Resizing(224, 224),    # Resize back to target size\n",
        "    ])\n",
        "\n",
        "    # Load training dataset\n",
        "    train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        validation_split=0.2,  # Reserve 20% for validation\n",
        "        subset=\"training\",\n",
        "        seed=23,  # Seed for reproducibility\n",
        "        image_size=(224, 224),\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    # Extract and store class names\n",
        "    class_names = train_dataset.class_names\n",
        "\n",
        "    # Apply data augmentation and normalization to training dataset\n",
        "    normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "    train_generator = train_dataset.map(\n",
        "        lambda x, y: (normalization_layer(data_augmentation(x)), y)\n",
        "    )\n",
        "\n",
        "    # Load validation dataset\n",
        "    val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        validation_split=0.2,  # Reserve 20% for validation\n",
        "        subset=\"validation\",\n",
        "        seed=23,  # Seed for reproducibility\n",
        "        image_size=(224, 224),\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    # Normalize validation dataset\n",
        "    val_generator = val_dataset.map(\n",
        "        lambda x, y: (normalization_layer(x), y)\n",
        "    )\n",
        "\n",
        "    # Prefetch datasets for improved performance\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    train_generator = train_generator.prefetch(buffer_size=AUTOTUNE)\n",
        "    val_generator = val_generator.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eAtJEHwetjx",
        "outputId": "280f658f-0096-431d-9b6d-6dab43780600"
      },
      "outputs": [],
      "source": [
        "data_preprocess()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVHI7UlnaCQw"
      },
      "source": [
        "# **Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdR3kpRYCjFF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP0U3Os6aEDV"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0g6htkVcNPZ"
      },
      "source": [
        "## **Summary of model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "lgQNLYutaHbw",
        "outputId": "f52270f9-63a6-43a1-d719-8acab7ddaacc"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP78WV3YcTMm"
      },
      "source": [
        "## **Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJKdfd-DfTu4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UT_ohHffXZy",
        "outputId": "d74e1a86-735d-4e03-8bcc-9d7a534c8c8b"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_and_compute_metrics(model, val_generator, class_names):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    # Iterate through the validation dataset\n",
        "    for images, labels in val_generator:\n",
        "        predictions = model.predict(images)  # Get predictions\n",
        "        y_true.extend(labels.numpy())  # Append true labels\n",
        "        y_pred.extend(np.argmax(predictions, axis=1))  # Append predicted class indices\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Compute metrics\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision_macro = precision_score(y_true, y_pred, average='macro')\n",
        "    recall_macro = recall_score(y_true, y_pred, average='macro')\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    precision_weighted = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall_weighted = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    class_report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "\n",
        "    return {\n",
        "        \"conf_matrix\": conf_matrix,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_macro\": precision_macro,\n",
        "        \"recall_macro\": recall_macro,\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"precision_weighted\": precision_weighted,\n",
        "        \"recall_weighted\": recall_weighted,\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"class_report\": class_report\n",
        "    }\n",
        "\n",
        "# Evaluate the model\n",
        "metrics = evaluate_model_and_compute_metrics(model, val_generator, class_names)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"Macro Precision: {metrics['precision_macro']:.4f}\")\n",
        "print(f\"Macro Recall: {metrics['recall_macro']:.4f}\")\n",
        "print(f\"Macro F1-Score: {metrics['f1_macro']:.4f}\")\n",
        "print(f\"Weighted Precision: {metrics['precision_weighted']:.4f}\")\n",
        "print(f\"Weighted Recall: {metrics['recall_weighted']:.4f}\")\n",
        "print(f\"Weighted F1-Score: {metrics['f1_weighted']:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\\n\", metrics['conf_matrix'])\n",
        "print(\"\\nClassification Report:\\n\", metrics['class_report'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUCEtgZPpmje"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.gridspec as gridspec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XpTQtspXpL91",
        "outputId": "562807bf-ab88-4b5f-f250-e099a86b6705"
      },
      "outputs": [],
      "source": [
        "def plot_class_report_with_images_and_text_tighter_with_grid(class_report, class_names, val_generator):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    # Parse the class_report string into a DataFrame\n",
        "    lines = class_report.split(\"\\n\")\n",
        "    report_data = []\n",
        "    for line in lines[2 : len(class_names) + 2]:  # Skip headers and totals\n",
        "        row = line.split()\n",
        "        if len(row) >= 5:  # Ensure valid row structure\n",
        "            class_name = \" \".join(row[:-4])  # Handles multi-word class names\n",
        "            precision, recall, f1_score, support = map(float, row[-4:])\n",
        "            report_data.append([class_name, precision, recall, f1_score, support])\n",
        "    class_report_df = pd.DataFrame(\n",
        "        report_data, columns=[\"Class Name\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n",
        "    )\n",
        "\n",
        "    # Extract one example image per class from the validation generator\n",
        "    example_images = {}\n",
        "    for images, labels in val_generator.unbatch().take(1500):  # Unbatch and take enough examples\n",
        "        label = labels.numpy()\n",
        "        if label not in example_images:\n",
        "            example_images[label] = images.numpy()\n",
        "        if len(example_images) == len(class_names):  # Stop if we have one image per class\n",
        "            break\n",
        "\n",
        "    # Set up the plot for 5 results per row\n",
        "    n_cols = 5\n",
        "    n_rows = int(np.ceil(len(class_names) / n_cols))\n",
        "    fig, axes = plt.subplots(\n",
        "        n_rows, n_cols * 2, figsize=(15, 20)\n",
        "    )  # Double columns for image + text, larger figure size\n",
        "    spec = gridspec.GridSpec(n_rows, n_cols * 2, figure=fig, width_ratios=[1, 3] * n_cols)\n",
        "\n",
        "    # Iterate through rows and columns\n",
        "    for idx, row in class_report_df.iterrows():\n",
        "        row_idx = idx // n_cols\n",
        "        col_idx = (idx % n_cols) * 2  # Double column index for image + text\n",
        "\n",
        "        # Show the image on the left\n",
        "        ax_image = axes[row_idx, col_idx] if n_rows > 1 else axes[col_idx]\n",
        "        if idx in example_images:\n",
        "            ax_image.imshow(example_images[idx])\n",
        "        ax_image.set_xticks([])  # Remove x ticks\n",
        "        ax_image.set_yticks([])  # Remove y ticks\n",
        "\n",
        "        # Show the metrics as text on the right\n",
        "        ax_text = axes[row_idx, col_idx + 1] if n_rows > 1 else axes[col_idx + 1]\n",
        "        metrics_text = (\n",
        "            f\"{row['Class Name']}\\n\"\n",
        "            f\"Precision: {row['Precision']:.2f}\\n\"\n",
        "            f\"Recall:    {row['Recall']:.2f}\\n\"\n",
        "            f\"F1-Score: {row['F1-Score']:.2f}\\n\"\n",
        "            f\"Support:  {int(row['Support'])}\"\n",
        "        )\n",
        "        ax_text.text(0, 0.5, metrics_text, fontsize=8, va=\"center\", ha=\"left\")\n",
        "        ax_text.axis(\"on\")  # Show grid around text\n",
        "        ax_text.set_xticks([])  # Remove x ticks\n",
        "        ax_text.set_yticks([])  # Remove y ticks\n",
        "\n",
        "\n",
        "    # Hide any unused axes\n",
        "    for ax in axes.flatten():\n",
        "        if not ax.has_data():\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.92)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_class_report_with_images_and_text_tighter_with_grid(metrics[\"class_report\"], class_names, val_generator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "8vmDWtwSkgUA",
        "outputId": "048a4112-2097-422c-8c5d-4c960695250a"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix_with_color_left_bar(conf_matrix, class_names):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    # Set up the figure and axes with larger size\n",
        "    fig, ax = plt.subplots(figsize=(20, 20))  # Increased figure size\n",
        "\n",
        "    # Add color bar on the left\n",
        "    cax = ax.matshow(conf_matrix, cmap='Blues')\n",
        "    cbar = fig.colorbar(cax, ax=ax, fraction=0.06, pad=0.04, location='left')\n",
        "\n",
        "    # Display axis numbers for classes\n",
        "    num_classes = len(class_names)\n",
        "    ax.set_xticks(range(1, num_classes + 1))\n",
        "    ax.set_yticks(range(1, num_classes + 1))\n",
        "    ax.set_xticklabels(range(1, num_classes + 1), rotation=90)  # Use numbers for axis\n",
        "    ax.set_yticklabels(range(1, num_classes + 1))  # Use numbers for axis\n",
        "    ax.xaxis.set_label_position(\"bottom\")\n",
        "    ax.xaxis.tick_bottom()\n",
        "\n",
        "    # Add class labels on the sides with corresponding numbers\n",
        "    side_labels = [f\"{i + 1}: {label}\" for i, label in enumerate(class_names)]\n",
        "    for idx, label in enumerate(side_labels):\n",
        "        ax.text(num_classes + 1.5, idx, label, va='center', ha='left', fontsize=8)\n",
        "\n",
        "    # Set axis labels\n",
        "    ax.set_xlabel(\"Predicted Labels\")\n",
        "    ax.set_ylabel(\"True Labels\")\n",
        "    plt.title(\"Confusion Matrix (Color Intensity)\")\n",
        "\n",
        "    # Adjust layout for the color bar and matrix\n",
        "    plt.subplots_adjust(left=0.1)  # Reserve space for the color bar\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_confusion_matrix_with_color_left_bar(metrics['conf_matrix'], class_names)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
